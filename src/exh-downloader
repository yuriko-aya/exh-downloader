#!/bin/bash

ver=20170101
uptodate=`curl -s https://raw.githubusercontent.com/yuriko-aya/exh-downloader/master/version`

if [ "$1" == "--update" ]; then
  if [[ $ver != $uptodate ]]; then
    echo "Updating..."
    sleep 3
    echo "Download and Installing update..."
    curl -s "https://raw.githubusercontent.com/yuriko-aya/exh-downloader/master/src/exh-downloader" > $HOME/bin/exh-downloader
    curl -s "https://raw.githubusercontent.com/yuriko-aya/exh-downloader/master/src/exhentai.cookie" > $HOME/.xhdownloader/exhentai.cookie
    echo "Done"
  exit
  else
    echo "Uptodate"
    exit
  fi
fi

if [[ $ver != $uptodate ]]; then
  echo An update is availabe.
  echo "to make sure everything work fine, please update"
  echo "run exh-downloader --update"
  exit
fi

if [ -z "$1" ]
  then
    read -rp $'Exhentai gallery link:' url
  else
    url="$1"
fi
if [ -z "$url" ]
  then
    echo "Please provide a link"
    echo "or --help for help"
    exit
fi
if [ "$url" == "--help" ]
  then
    echo "ExHentai Downloader for Linux"
    echo " "
    echo "Usage:"
    echo "  exh-downloader gallery_url"
    echo "  example: exh-downloader exhentai.org/g/918667/f611a5c353/"
    echo "  exh-downloader --help for this help"
    exit
fi
realurl="`echo $url | grep 'exhentai.org'`"
if [ -z "$url" ]
  then
    echo "Please provide a link"
    exit
fi
if [ -z "$realurl" ]
  then
    echo "Please provide a valid exhentai link with http"
    echo "example: exhentai.org/g/918667/f611a5c353/"
    exit
fi
gid="`echo $url | sed -e 's|/| |g' | awk '{print $4}'`"
echo "Starting ExHentai Downloader Linux"
sleep 1
echo "Downloading from $url"
sleep 1
echo "Fetching metadata..."
page="`wget -c -q --load-cookies=$HOME/.xhdownloader/exhentai.cookie "$url" -O- | hxselect -i "td.gdt2" | lynx -stdin -dump | awk {'print $9'}`"
if [[ $page -lt 1 ]]
  then
    echo "ERROR gallery not found"
    echo "Are you sure the link was correct?"
    exit
fi
pagegall="`expr $page / 40`"
wget -c -q --load-cookies=$HOME/.xhdownloader/exhentai.cookie "$url" -O- | hxselect -i "title" | sed 's|<title>||;s| - ExHentai.org</title>||' > $HOME/.xhdownloader/$gid.title
extitle="`cat $HOME/.xhdownloader/$gid.title`"
mkdir "$extitle"
cd "$extitle"
echo "Title: $extitle"
echo "length: $page"

if [ $pagegall -ge 1 ]
	then
		echo "Downloading Multiple page gallery"
		sleep 5
		gallnum=0
		while [[ $gallnum -le $pagegall ]]; do
			wget -c --load-cookies=$HOME/.xhdownloader/exhentai.cookie "$url"?p=$gallnum -O- | hxselect -i  "div.gdtm a" | lynx -stdin -dump > $HOME/.xhdownloader/$gid.scrap
			cat $HOME/.xhdownloader/$gid.scrap | grep exhentai | awk {'print $2'} > $HOME/.xhdownloader/$gid.gall
			while read line; do
				wget -c -q --load-cookies=$HOME/.xhdownloader/exhentai.cookie "$line" -O- | hxnormalize | egrep "src.*jpg|src.*png" | grep -v "exhentai" | sed 's|src="||;s|.$||' | wget -c --load-cookies=$HOME/.xhdownloader/exhentai.cookie -i-
			done < $HOME/.xhdownloader/$gid.gall
			let gallnum=$gallnum+1
		done
	else
		echo "Downloading single page gallery"
		sleep 5
		wget -c --load-cookies=$HOME/.xhdownloader/exhentai.cookie "$url" -O- | hxselect -i  "div.gdtm a" | lynx -stdin -dump > $HOME/.xhdownloader/$gid.scrap
		cat $HOME/.xhdownloader/$gid.scrap | grep exhentai | awk {'print $2'} > $HOME/.xhdownloader/$gid.gall
		while read line; do
			wget -c -q --load-cookies=$HOME/.xhdownloader/exhentai.cookie "$line" -O- | hxnormalize | egrep "src.*jpg|src.*png" | grep -v "exhentai" | sed 's|src="||;s|.$||' | wget -c --load-cookies=$HOME/.xhdownloader/exhentai.cookie -i-
		done < $HOME/.xhdownloader/$gid.gall
fi
rm $HOME/.xhdownloader/$gid.scrap
rm $HOME/.xhdownloader/$gid.gall
rm $HOME/.xhdownloader/$gid.title
cd ../
